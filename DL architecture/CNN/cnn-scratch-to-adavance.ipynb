{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c30fb57",
   "metadata": {
    "papermill": {
     "duration": 0.005512,
     "end_time": "2024-01-07T16:30:02.791123",
     "exception": false,
     "start_time": "2024-01-07T16:30:02.785611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Convolutional Neural Networks\n",
    "\n",
    "* Inspired by biological brain part visual cortex\n",
    "\n",
    "* Mostly performed good on grid like data structure. example images, time series etc.\n",
    "\n",
    "* It has been sweeping the board in competitions for the servel years, but perhaps its first big success came in the late 90's when Yann LeCun used it to solve MNIST with 99.5% accuracy.\n",
    "\n",
    "* A convolutional neural network (CNN) takes an input image and classifies it into any of the output classes. Each image passes through a series of different layers – primarily convolutional layers, pooling layers, and fully connected layers. The below picture summarizes what an image passes through in a CNN:\n",
    "\n",
    "\n",
    "![](https://blog.paperspace.com/content/images/size/w1000/2021/05/image-32.png)\n",
    "\n",
    "\n",
    "* I will implement CNN from scratch in PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4099798f",
   "metadata": {
    "papermill": {
     "duration": 0.004815,
     "end_time": "2024-01-07T16:30:02.801549",
     "exception": false,
     "start_time": "2024-01-07T16:30:02.796734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df92bb33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T16:30:02.813195Z",
     "iopub.status.busy": "2024-01-07T16:30:02.812830Z",
     "iopub.status.idle": "2024-01-07T16:30:06.271611Z",
     "shell.execute_reply": "2024-01-07T16:30:06.270619Z"
    },
    "papermill": {
     "duration": 3.467526,
     "end_time": "2024-01-07T16:30:06.274094",
     "exception": false,
     "start_time": "2024-01-07T16:30:02.806568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97147c4b",
   "metadata": {
    "papermill": {
     "duration": 0.004752,
     "end_time": "2024-01-07T16:30:06.283936",
     "exception": false,
     "start_time": "2024-01-07T16:30:06.279184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Convolutional Layer\n",
    "* used to extract features from image\n",
    "* convol operation perform between image and filter as shown in image\n",
    "![](https://blog.paperspace.com/content/images/size/w1000/2021/08/Convolutional.webp)\n",
    "* diffrent filters are used to extract diffrent kind of features (weights are tuned by training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb94efb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T16:30:06.294742Z",
     "iopub.status.busy": "2024-01-07T16:30:06.294300Z",
     "iopub.status.idle": "2024-01-07T16:30:06.300608Z",
     "shell.execute_reply": "2024-01-07T16:30:06.299822Z"
    },
    "papermill": {
     "duration": 0.013862,
     "end_time": "2024-01-07T16:30:06.302501",
     "exception": false,
     "start_time": "2024-01-07T16:30:06.288639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### code for convolue \n",
    "def apply_kernel(image, kernel):\n",
    "    ri, ci = image.shape       # image dimensions\n",
    "    rk, ck = kernel.shape      # kernel dimensions\n",
    "    ro, co = ri-rk+1, ci-ck+1  # output dimensions\n",
    "    output = torch.zeros([ro, co])\n",
    "    for i in range(ro): \n",
    "        for j in range(co):\n",
    "            output[i,j] = torch.sum(image[i:i+rk,j:j+ck] * kernel)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a2728",
   "metadata": {
    "papermill": {
     "duration": 0.0045,
     "end_time": "2024-01-07T16:30:06.311808",
     "exception": false,
     "start_time": "2024-01-07T16:30:06.307308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Pooling Layer\n",
    "* used to reduce size of any image while maintaining most imp features\n",
    "* common type of pooling layers are max and average pooling which take max and average value respectively from the given size of the filter\n",
    "![](https://blog.paperspace.com/content/images/2021/05/image-35.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b3bc96",
   "metadata": {
    "papermill": {
     "duration": 0.004472,
     "end_time": "2024-01-07T16:30:06.320971",
     "exception": false,
     "start_time": "2024-01-07T16:30:06.316499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7f19222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T16:30:06.331846Z",
     "iopub.status.busy": "2024-01-07T16:30:06.331273Z",
     "iopub.status.idle": "2024-01-07T16:30:06.381807Z",
     "shell.execute_reply": "2024-01-07T16:30:06.380824Z"
    },
    "papermill": {
     "duration": 0.058244,
     "end_time": "2024-01-07T16:30:06.383927",
     "exception": false,
     "start_time": "2024-01-07T16:30:06.325683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading CIFAR-10 Dataset. Dataset has 60,000 color images beloging to 10 diffrent classes.\n",
    "\n",
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6002ac89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T16:30:06.395754Z",
     "iopub.status.busy": "2024-01-07T16:30:06.394789Z",
     "iopub.status.idle": "2024-01-07T16:30:26.298340Z",
     "shell.execute_reply": "2024-01-07T16:30:26.297547Z"
    },
    "papermill": {
     "duration": 19.911731,
     "end_time": "2024-01-07T16:30:26.300633",
     "exception": false,
     "start_time": "2024-01-07T16:30:06.388902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:15<00:00, 11203538.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Use transforms.compose method to reformat images for modeling,\n",
    "# and save to variable all_transforms for later use\n",
    "all_transforms = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                                          std=[0.2023, 0.1994, 0.2010])\n",
    "                                     ])\n",
    "# Create Training dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                             train = True,\n",
    "                                             transform = all_transforms,\n",
    "                                             download = True)\n",
    "\n",
    "# Create Testing dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
    "                                            train = False,\n",
    "                                            transform = all_transforms,\n",
    "                                            download=True)\n",
    "\n",
    "# Instantiate loader objects to facilitate processing\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b74d084",
   "metadata": {
    "papermill": {
     "duration": 0.011762,
     "end_time": "2024-01-07T16:30:26.324666",
     "exception": false,
     "start_time": "2024-01-07T16:30:26.312904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Class implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97aedc85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T16:30:26.349692Z",
     "iopub.status.busy": "2024-01-07T16:30:26.349371Z",
     "iopub.status.idle": "2024-01-07T16:30:26.359154Z",
     "shell.execute_reply": "2024-01-07T16:30:26.358353Z"
    },
    "papermill": {
     "duration": 0.024489,
     "end_time": "2024-01-07T16:30:26.360971",
     "exception": false,
     "start_time": "2024-01-07T16:30:26.336482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## scratch Cnn class \n",
    "class ScratchCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(ScratchCNN, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.max_pool2(out)\n",
    "                \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd97ca07",
   "metadata": {
    "papermill": {
     "duration": 0.011631,
     "end_time": "2024-01-07T16:30:26.384337",
     "exception": false,
     "start_time": "2024-01-07T16:30:26.372706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Set Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b45b74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T16:30:26.409551Z",
     "iopub.status.busy": "2024-01-07T16:30:26.409176Z",
     "iopub.status.idle": "2024-01-07T16:30:26.587015Z",
     "shell.execute_reply": "2024-01-07T16:30:26.586255Z"
    },
    "papermill": {
     "duration": 0.193244,
     "end_time": "2024-01-07T16:30:26.589344",
     "exception": false,
     "start_time": "2024-01-07T16:30:26.396100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ScratchCNN(num_classes).to(device)\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer with optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d398b06",
   "metadata": {
    "papermill": {
     "duration": 0.011665,
     "end_time": "2024-01-07T16:30:26.613146",
     "exception": false,
     "start_time": "2024-01-07T16:30:26.601481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e3e10de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T16:30:26.638742Z",
     "iopub.status.busy": "2024-01-07T16:30:26.638403Z",
     "iopub.status.idle": "2024-01-07T16:35:23.872285Z",
     "shell.execute_reply": "2024-01-07T16:35:23.871378Z"
    },
    "papermill": {
     "duration": 297.262149,
     "end_time": "2024-01-07T16:35:23.887691",
     "exception": false,
     "start_time": "2024-01-07T16:30:26.625542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.6282\n",
      "Epoch [2/20], Loss: 1.5802\n",
      "Epoch [3/20], Loss: 0.8911\n",
      "Epoch [4/20], Loss: 1.2056\n",
      "Epoch [5/20], Loss: 1.2577\n",
      "Epoch [6/20], Loss: 1.1080\n",
      "Epoch [7/20], Loss: 1.3959\n",
      "Epoch [8/20], Loss: 0.7590\n",
      "Epoch [9/20], Loss: 0.9595\n",
      "Epoch [10/20], Loss: 0.8614\n",
      "Epoch [11/20], Loss: 0.7860\n",
      "Epoch [12/20], Loss: 0.9462\n",
      "Epoch [13/20], Loss: 0.9958\n",
      "Epoch [14/20], Loss: 1.3702\n",
      "Epoch [15/20], Loss: 0.3938\n",
      "Epoch [16/20], Loss: 0.9042\n",
      "Epoch [17/20], Loss: 0.6285\n",
      "Epoch [18/20], Loss: 0.6525\n",
      "Epoch [19/20], Loss: 0.4563\n",
      "Epoch [20/20], Loss: 0.5478\n"
     ]
    }
   ],
   "source": [
    "# We use the pre-defined number of epochs to determine how many iterations to train the network on\n",
    "for epoch in range(num_epochs):\n",
    "\t#Load in the data in batches using the train_loader object\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e8d45",
   "metadata": {
    "papermill": {
     "duration": 0.013328,
     "end_time": "2024-01-07T16:35:23.914485",
     "exception": false,
     "start_time": "2024-01-07T16:35:23.901157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ec50d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-07T16:35:23.942686Z",
     "iopub.status.busy": "2024-01-07T16:35:23.942339Z",
     "iopub.status.idle": "2024-01-07T16:35:37.498940Z",
     "shell.execute_reply": "2024-01-07T16:35:37.497932Z"
    },
    "papermill": {
     "duration": 13.57339,
     "end_time": "2024-01-07T16:35:37.501137",
     "exception": false,
     "start_time": "2024-01-07T16:35:23.927747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 50000 train images: 82.76 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} train images: {} %'.format(50000, 100 * correct / total))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33b091",
   "metadata": {
    "papermill": {
     "duration": 0.013276,
     "end_time": "2024-01-07T16:35:37.528183",
     "exception": false,
     "start_time": "2024-01-07T16:35:37.514907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Advantage of CNN\n",
    "* Fewer parameters: A small set of parameters (the kernel) is used to calculate outputs of the entire image, so the model has much fewer parameters compared to a fully connected layer.\n",
    "\n",
    "* Sparsity of connections: In each layer, each output element only depends on a small number of input elements, which makes the forward and backward passes more efficient.\n",
    "\n",
    "* Parameter sharing and spatial invariance: The features learned by a kernel in one part of the image can be used to detect similar pattern in a different part of another image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd12e63d",
   "metadata": {
    "papermill": {
     "duration": 0.013107,
     "end_time": "2024-01-07T16:35:37.554701",
     "exception": false,
     "start_time": "2024-01-07T16:35:37.541594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 67771835,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 339.443291,
   "end_time": "2024-01-07T16:35:38.890664",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-07T16:29:59.447373",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
